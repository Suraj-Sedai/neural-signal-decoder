{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suraj-Sedai/neural-signal-decoder/blob/main/notebook/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Signal Decoder (Simulated)\n",
        "\n",
        "The Neural Signal Decoder (Simulated) project is a complete, end‑to‑end implementation of a neural time‑series decoding system inspired by Brain–Computer Interface (BCI) research. The system is designed to translate multichannel EEG‑like signals into discrete control actions using deep learning sequence models."
      ],
      "metadata": {
        "id": "NnoKwoClBbvo"
      },
      "id": "NnoKwoClBbvo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##System Architecture\n",
        "\n",
        "The Neural Signal Decoder follows a modular pipeline architecture:\n",
        "\n",
        "\n",
        "```NEURAL SIGNAL → PREPROCESSING → TEMPORAL ENCODER → CLASSIFIER → ACTION OUTPUT```\n"
      ],
      "metadata": {
        "id": "RDxp6UUWBl8f"
      },
      "id": "RDxp6UUWBl8f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ECE Signal"
      ],
      "metadata": {
        "id": "mgwDrbH8B2on"
      },
      "id": "mgwDrbH8B2on"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7798d46d"
      },
      "source": [
        "### Explanation of `simulate_eeg_sample` Function\n",
        "\n",
        "This Python code defines a function `simulate_eeg_sample` which generates a simulated EEG-like signal based on a given `class_id`. It's designed to mimic neural signals with different frequency characteristics depending on the intended 'action' (represented by `class_id`).\n",
        "\n",
        "#### Function Parameters:\n",
        "\n",
        "*   **`class_id`**: An integer representing the 'action' or mental state (0 for 'Left', 1 for 'Right', 2 for 'Up', 3 for 'Down'). Each class is associated with a distinct frequency band.\n",
        "*   **`num_channels`**: The number of simulated EEG channels.\n",
        "*   **`num_timesteps`**: The number of data points (samples) in the time series for each channel.\n",
        "*   **`sampling_rate`**: The number of samples per second (default is 256 Hz, common in EEG).\n",
        "\n",
        "#### How the Signal is Generated (Mathematical Explanation):\n",
        "\n",
        "1.  **Time Axis (`t`)**:\n",
        "\n",
        "    ```python\n",
        "    t = np.arange(num_timesteps) / sampling_rate\n",
        "    ```\n",
        "\n",
        "    *   `np.arange(num_timesteps)` creates an array of integers from `0` to `num_timesteps - 1`. These represent the sample indices.\n",
        "    *   Dividing by `sampling_rate` converts these sample indices into actual time values in seconds. For example, if `sampling_rate` is 256, the first sample is at `t=0`, the second at `t=1/256`, the third at `t=2/256`, and so on.\n",
        "\n",
        "2.  **Class-Dependent Frequency Bands (`freq_bands`)**:\n",
        "\n",
        "    ```python\n",
        "    freq_bands = {\n",
        "        0: (7, 10),    # Left (e.g., Alpha band)\n",
        "        1: (11, 14),   # Right (e.g., Low Beta band)\n",
        "        2: (15, 20),   # Up (e.g., Mid Beta band)\n",
        "        3: (20, 25)    # Down (e.g., High Beta band)\n",
        "    }\n",
        "    low_f, high_f = freq_bands[class_id]\n",
        "    ```\n",
        "\n",
        "    This dictionary maps each `class_id` to a specific frequency range (`low_f`, `high_f`). When generating the signal for a given `class_id`, the function picks a random frequency within this band.\n",
        "\n",
        "3.  **Signal Generation per Channel**:\n",
        "\n",
        "    The core of the simulation happens in a loop, generating a signal for each `num_channels`.\n",
        "\n",
        "    *   **Frequency (`freq`) and Phase (`phase`) Selection**:\n",
        "\n",
        "        ```python\n",
        "        freq = np.random.uniform(low_f, high_f)\n",
        "        phase = np.random.uniform(0, 2 * np.pi)\n",
        "        ```\n",
        "\n",
        "        For each channel, a random frequency (`freq`) is chosen uniformly from the `[low_f, high_f]` band. A random phase (`phase`) is also chosen uniformly between `0` and `2π` radians. This randomness helps make each channel slightly different, as would be expected in real EEG.\n",
        "\n",
        "    *   **Sine Wave Generation (`wave`)**:\n",
        "\n",
        "        ```python\n",
        "        wave = np.sin(2 * np.pi * freq * t + phase)\n",
        "        ```\n",
        "\n",
        "        This is the mathematical formula for a pure sine wave:\n",
        "        `A * sin(2πft + φ)`\n",
        "        Where:\n",
        "        *   `A` is the amplitude (implicitly 1 here).\n",
        "        *   `f` is the `freq` chosen for the channel.\n",
        "        *   `t` is the time axis array.\n",
        "        *   `φ` is the `phase` chosen for the channel.\n",
        "\n",
        "        This generates a clean oscillatory signal specific to the `class_id`'s frequency band.\n",
        "\n",
        "    *   **Noise Generation (`noise`)**:\n",
        "\n",
        "        ```python\n",
        "        noise = np.random.normal(0, 0.3, size=num_timesteps)\n",
        "        ```\n",
        "\n",
        "        This adds random noise to the clean sine wave. `np.random.normal(0, 0.3, ...)` generates samples from a normal (Gaussian) distribution with:\n",
        "        *   Mean (`μ`) = 0\n",
        "        *   Standard Deviation (`σ`) = 0.3\n",
        "\n",
        "        This simulates the inherent randomness and interference present in real-world biological signals.\n",
        "\n",
        "    *   **Combined Signal**:\n",
        "\n",
        "        ```python\n",
        "        signal[ch] = wave + noise\n",
        "        ```\n",
        "\n",
        "        The final signal for each channel is the sum of the pure sine wave and the Gaussian noise. This creates a more realistic EEG-like waveform where the underlying brain activity (the sine wave) is partially obscured by noise.\n",
        "\n",
        "#### Return Value (`signal`)\n",
        "\n",
        "*   The function returns a `numpy.ndarray` with the shape `(num_channels, num_timesteps)`, where each row corresponds to a different channel and each column to a time step. This array contains the simulated EEG data."
      ],
      "id": "7798d46d"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_eeg_sample(\n",
        "    class_id: int,\n",
        "    num_channels: int,\n",
        "    num_timesteps: int,\n",
        "    sampling_rate: int = 256\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        signal: np.ndarray of shape (num_channels, num_timesteps)\n",
        "    \"\"\"\n",
        "\n",
        "    # Time axis\n",
        "    t = np.arange(num_timesteps) / sampling_rate\n",
        "\n",
        "    # Class-dependent frequency bands\n",
        "    freq_bands = {\n",
        "        0: (7, 10),    # Left\n",
        "        1: (11, 14),   # Right\n",
        "        2: (15, 20),   # Up\n",
        "        3: (20, 25)    # Down\n",
        "    }\n",
        "\n",
        "    low_f, high_f = freq_bands[class_id]\n",
        "\n",
        "    signal = np.zeros((num_channels, num_timesteps))\n",
        "\n",
        "    for ch in range(num_channels):\n",
        "        freq = np.random.uniform(low_f, high_f)\n",
        "        phase = np.random.uniform(0, 2 * np.pi)\n",
        "\n",
        "        wave = np.sin(2 * np.pi * freq * t + phase)\n",
        "        noise = np.random.normal(0, 0.3, size=num_timesteps)\n",
        "\n",
        "        signal[ch] = wave + noise\n",
        "\n",
        "    return signal\n"
      ],
      "metadata": {
        "id": "yUrYUi_QBhZ6"
      },
      "id": "yUrYUi_QBhZ6",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7357c94"
      },
      "source": [
        "### Module 2: Signal Pre-processing - Connecting Code to Documentation\n",
        "\n",
        "The `normalize_channels` and `window_signal` functions are integral to this stage.\n",
        "\n",
        "1.  **`normalize_channels` Function**: This function directly addresses the 'PREPROCESSING' step in your overall system architecture (`NEURAL SIGNAL → PREPROCESSING → TEMPORAL ENCODER → CLASSIFIER → ACTION OUTPUT`). It standardizes the signal across each channel, ensuring that variations in amplitude between different channels do not disproportionately affect downstream models. This normalization step is vital for robust model performance, especially with sensitive neural data.\n",
        "\n",
        "2.  **`window_signal` Function**: Following normalization, the continuous pre-processed signal is then segmented into fixed-size 'windows' or 'epochs' using the `window_signal` function. This process is essential for sequence models, which typically require input data in discrete, fixed-length segments. By creating these windows, the function prepares the data for the 'TEMPORAL ENCODER' stage, allowing the model to learn patterns within specific timeframes of the neural activity."
      ],
      "id": "c7357c94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "914d1e1d"
      },
      "source": [
        "### `normalize_channels` Function\n",
        "\n",
        "This function takes a 2D NumPy array representing multi-channel signals (e.g., EEG data) and performs channel-wise standardization (Z-score normalization). This is a common preprocessing step to ensure that each channel contributes equally to subsequent analysis or model training, regardless of its original amplitude scale.\n",
        "\n",
        "#### Function Parameters:\n",
        "\n",
        "*   **`signal`**: A `numpy.ndarray` of shape `(C, T)`, where `C` is the number of channels and `T` is the number of time steps (samples).\n",
        "\n",
        "#### How Normalization Works:\n",
        "\n",
        "1.  **Iterate through Channels**: The function loops through each channel of the input `signal`.\n",
        "2.  **Calculate Mean and Standard Deviation**: For each channel `c`:\n",
        "    *   `mean = signal[c].mean()`: The average value of the signal across all time steps for that specific channel is calculated.\n",
        "    *   `std = signal[c].std() + 1e-8`: The standard deviation of the signal for that channel is calculated. A small constant `1e-8` is added to the standard deviation to prevent division by zero in case a channel has no variance (i.e., all values are the same).\n",
        "3.  **Apply Standardization**: The standardization formula is applied to each data point in the channel:\n",
        "    *   `normalized[c] = (signal[c] - mean) / std`\n",
        "    This transforms the data such that each channel will have a mean of approximately 0 and a standard deviation of approximately 1.\n",
        "\n",
        "#### Return Value (`normalized_signal`)\n",
        "\n",
        "*   A `numpy.ndarray` of the same shape `(C, T)` as the input `signal`, containing the standardized (normalized) signal data for all channels.\n"
      ],
      "id": "914d1e1d"
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_channels(signal: np.ndarray):\n",
        "    \"\"\"\n",
        "    signal: np.ndarray of shape (C, T)\n",
        "\n",
        "    returns:\n",
        "        normalized_signal: np.ndarray of shape (C, T)\n",
        "    \"\"\"\n",
        "    C, T = signal.shape\n",
        "    normalized = np.zeros_like(signal)\n",
        "\n",
        "    for c in range(C):\n",
        "        mean = signal[c].mean()\n",
        "        std = signal[c].std() + 1e-8\n",
        "        normalized[c] = (signal[c] - mean) / std\n",
        "\n",
        "    return normalized\n"
      ],
      "metadata": {
        "id": "A5h31yxBke7D"
      },
      "id": "A5h31yxBke7D",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `window_signal` Function\n",
        "\n",
        "This function takes a continuous multi-channel signal and divides it into overlapping or non-overlapping segments (windows) of a fixed size. This technique, known as \"windowing\" or \"sliding window,\" is crucial in time-series analysis for preparing data for sequence models, allowing the model to process smaller, fixed-length chunks of the signal.\n",
        "\n",
        "#### Function Parameters:\n",
        "\n",
        "*   **`signal`**: A `numpy.ndarray` of shape `(C, T)`, where `C` is the number of channels and `T` is the total number of time steps.\n",
        "*   **`window_size`**: An integer specifying the length of each window (number of time steps).\n",
        "*   **`stride`**: An integer specifying the number of time steps to advance for the start of the next window. If `stride` equals `window_size`, the windows are non-overlapping. If `stride` is less than `window_size`, the windows overlap.\n",
        "\n",
        "#### How Windowing Works:\n",
        "\n",
        "1.  **Initialize**: An empty list `windows` is created to store the generated signal segments.\n",
        "2.  **Slide the Window**: The function iterates from the beginning of the signal (`start = 0`) up to a point where a full `window_size` can still be extracted.\n",
        "    *   The loop continues as long as `start` is such that `start + window_size` does not exceed the total number of time steps `T`.\n",
        "    *   `start` is incremented by `stride` in each iteration, effectively sliding the window across the signal.\n",
        "3.  **Extract Window**: In each iteration, a segment of the `signal` is extracted:\n",
        "    *   `signal[:, start:end]` selects all channels (`:`) and the time steps from `start` to `end` (exclusive of `end`), where `end = start + window_size`.\n",
        "    *   This extracted segment, which has the shape `(C, window_size)`, is appended to the `windows` list.\n",
        "4.  **Stack Windows**: After all windows have been extracted, `np.stack(windows)` converts the list of 2D arrays into a single 3D NumPy array.\n",
        "\n",
        "#### Return Value (`windows`)\n",
        "\n",
        "*   A `numpy.ndarray` of shape `(N, C, window_size)`, where:\n",
        "    *   `N` is the total number of windows created.\n",
        "    *   `C` is the number of channels.\n",
        "    *   `window_size` is the length of each individual window."
      ],
      "metadata": {
        "id": "-p_c7W6Bl70L"
      },
      "id": "-p_c7W6Bl70L"
    },
    {
      "cell_type": "code",
      "source": [
        "def window_signal(signal: np.ndarray, window_size: int, stride: int):\n",
        "    \"\"\"\n",
        "    signal: np.ndarray of shape (C, T)\n",
        "\n",
        "    returns:\n",
        "        windows: np.ndarray of shape (N, C, window_size)\n",
        "    \"\"\"\n",
        "    C, T = signal.shape\n",
        "    windows = []\n",
        "\n",
        "    for start in range(0, T - window_size + 1, stride):\n",
        "        end = start + window_size\n",
        "        windows.append(signal[:, start:end])\n",
        "\n",
        "    return np.stack(windows)\n"
      ],
      "metadata": {
        "id": "frkNOtIskk5F"
      },
      "id": "frkNOtIskk5F",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f941b82a"
      },
      "source": [
        "### `SimulatedEEGDataset` Class\n",
        "\n",
        "This Python class, `SimulatedEEGDataset`, is a custom implementation of PyTorch's `Dataset` class. It's designed to generate and prepare a dataset of simulated EEG-like signals, which can then be easily loaded and used for training deep learning models in PyTorch. It integrates the previously defined `simulate_eeg_sample`, `normalize_channels`, and `window_signal` functions to create a full, ready-to-use dataset.\n",
        "\n",
        "#### Class Parameters (Constructor `__init__`):\n",
        "\n",
        "*   **`num_samples_per_class`**: An integer specifying how many base EEG signals to simulate for each of the 4 defined `class_id`s (0, 1, 2, 3).\n",
        "*   **`num_channels`**: The number of simulated EEG channels for each sample.\n",
        "*   **`total_timesteps`**: The total length (number of time points) of the raw simulated signal before windowing.\n",
        "*   **`window_size`**: The length of each window (segment) into which the `total_timesteps` signal will be divided.\n",
        "*   **`stride`**: The step size to move the window. This determines if windows overlap (`stride < window_size`) or are contiguous (`stride == window_size`).\n",
        "\n",
        "#### How the Dataset is Constructed (`__init__` method):\n",
        "\n",
        "1.  **Initialization**: Two empty lists, `self.windows` and `self.labels`, are created to store the processed signal windows and their corresponding class labels.\n",
        "2.  **Looping Through Classes and Samples**: The code iterates four times (for `class_id` 0, 1, 2, and 3), and for each `class_id`, it generates `num_samples_per_class` individual EEG signals.\n",
        "    *   **Signal Simulation**: `simulate_eeg_sample()` is called to generate a raw multi-channel signal based on the current `class_id`, `num_channels`, and `total_timesteps`.\n",
        "    *   **Channel Normalization**: The raw `signal` is then passed to `normalize_channels()` to standardize each channel, ensuring consistent amplitude scales.\n",
        "    *   **Signal Windowing**: The normalized `signal` is then segmented into fixed-size windows using `window_signal()`, based on `window_size` and `stride`.\n",
        "3.  **Collecting Windows and Labels**: Each generated window (`w`) from `window_signal` is appended to `self.windows`, and its corresponding `class_id` is appended to `self.labels`.\n",
        "4.  **Tensor Conversion**: After all signals for all classes have been processed, the collected `self.windows` and `self.labels` lists are converted into PyTorch tensors:\n",
        "    *   `self.windows` becomes a `torch.tensor` of `float32` type, with a shape typically `(N_total_windows, num_channels, window_size)`.\n",
        "    *   `self.labels` becomes a `torch.tensor` of `long` type, containing the class ID for each window.\n",
        "\n",
        "#### `__len__` Method:\n",
        "\n",
        "*   This standard PyTorch `Dataset` method returns the total number of samples (windows) in the dataset, which is simply the length of the `self.labels` list.\n",
        "\n",
        "#### `__getitem__` Method:\n",
        "\n",
        "*   This standard PyTorch `Dataset` method allows you to access a specific sample from the dataset by its `idx` (index).\n",
        "*   It returns a tuple containing a signal `window` (a `torch.Tensor` of shape `(num_channels, window_size)`) and its corresponding `label` (a `torch.Tensor` representing the `class_id`).\n",
        "\n",
        "In essence, this class encapsulates the entire data generation and preprocessing pipeline, making it easy to create batched data loaders for training neural networks."
      ],
      "id": "f941b82a"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SimulatedEEGDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_samples_per_class: int,\n",
        "        num_channels: int,\n",
        "        total_timesteps: int,\n",
        "        window_size: int,\n",
        "        stride: int\n",
        "    ):\n",
        "        self.windows = []\n",
        "        self.labels = []\n",
        "\n",
        "        for class_id in range(4):\n",
        "            for _ in range(num_samples_per_class):\n",
        "                signal = simulate_eeg_sample(\n",
        "                    class_id=class_id,\n",
        "                    num_channels=num_channels,\n",
        "                    num_timesteps=total_timesteps\n",
        "                )\n",
        "\n",
        "                signal = normalize_channels(signal)\n",
        "                windows = window_signal(signal, window_size, stride)\n",
        "\n",
        "                for w in windows:\n",
        "                    self.windows.append(w)\n",
        "                    self.labels.append(class_id)\n",
        "\n",
        "        self.windows = torch.tensor(self.windows, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.windows[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "-yvuMI_FuiQR"
      },
      "id": "-yvuMI_FuiQR",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7544e2b"
      },
      "source": [
        "### Explanation of Dataset Instantiation and First Sample Access\n",
        "\n",
        "This code snippet demonstrates how to instantiate the `SimulatedEEGDataset` and access its first generated sample. It serves as a quick test to ensure the dataset is created correctly and can provide data in the expected format.\n",
        "\n",
        "1.  **Dataset Instantiation (`ds = SimulatedEEGDataset(...)`)**:\n",
        "    *   An instance of `SimulatedEEGDataset` is created with specific parameters:\n",
        "        *   `num_samples_per_class=5`: For each of the 4 `class_id`s, 5 base EEG signals will be simulated.\n",
        "        *   `num_channels=16`: Each simulated signal will have 16 channels.\n",
        "        *   `total_timesteps=1024`: Each raw simulated signal will have 1024 time points.\n",
        "        *   `window_size=256`: The signals will be segmented into windows of 256 time points.\n",
        "        *   `stride=128`: The windows will overlap by 128 time points (since `stride` is half of `window_size`).\n",
        "    *   During this instantiation, the `__init__` method of the `SimulatedEEGDataset` class is executed, which internally calls `simulate_eeg_sample`, `normalize_channels`, and `window_signal` to generate and preprocess all the data, storing it as PyTorch tensors.\n",
        "\n",
        "2.  **Accessing the First Sample (`x, y = ds[0]`)**:\n",
        "    *   The `__getitem__(0)` method of the dataset is implicitly called to retrieve the sample at index `0`.\n",
        "    *   `x` will receive the first signal window (a `torch.Tensor` of shape `(num_channels, window_size)`).\n",
        "    *   `y` will receive the label (class ID) corresponding to that first window (a `torch.Tensor` containing a single integer).\n",
        "\n",
        "3.  **Printing Shape and Label (`print(x.shape, y)`)**:\n",
        "    *   This line prints the shape of the `x` tensor (the signal window) and the value of the `y` tensor (the label).\n",
        "    *   The expected output, `torch.Size([16, 256]) tensor(0)`, confirms that `x` has 16 channels and 256 time steps, and `y` has a label of `0` (corresponding to the first `class_id`).\n",
        "\n",
        "This small test verifies that the data generation and loading pipeline, as implemented in `SimulatedEEGDataset`, is functioning as expected, producing correctly shaped signal windows and their corresponding labels."
      ],
      "id": "e7544e2b"
    },
    {
      "cell_type": "code",
      "source": [
        "ds = SimulatedEEGDataset(\n",
        "    num_samples_per_class=5,\n",
        "    num_channels=16,\n",
        "    total_timesteps=1024,\n",
        "    window_size=256,\n",
        "    stride=128\n",
        ")\n",
        "\n",
        "x, y = ds[0]\n",
        "print(x.shape, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwanLkLzvB6T",
        "outputId": "14edf457-a195-4fb1-92cd-54d773cba8d7"
      },
      "id": "SwanLkLzvB6T",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 256]) tensor(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-112950328.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  self.windows = torch.tensor(self.windows, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f546bd1f"
      },
      "source": [
        "### `LSTMDecoder` Class (Module 9: Temporal Encoder & Classifier)\n",
        "\n",
        "This `LSTMDecoder` class represents the core of the neural signal decoding system, combining both the 'Temporal Encoder' and 'Classifier' stages of your project's architecture (`NEURAL SIGNAL → PREPROCESSING → TEMPORAL ENCODER → CLASSIFIER → ACTION OUTPUT`). It utilizes a Long Short-Term Memory (LSTM) network to process the sequential EEG-like data and a linear layer to classify the output into discrete actions.\n",
        "\n",
        "#### Class Parameters (Constructor `__init__`):\n",
        "\n",
        "*   **`num_channels`**: The number of input channels in the preprocessed signal windows. This will be the `input_size` for the LSTM layer.\n",
        "*   **`hidden_size`**: The number of features in the hidden state `h` of the LSTM. This determines the capacity of the LSTM to learn complex temporal patterns.\n",
        "*   **`num_layers`**: The number of recurrent layers in the LSTM. A higher number allows the model to learn more hierarchical representations from the sequence data.\n",
        "*   **`num_classes`**: The number of possible output classes (actions), which is 4 in your case (Left, Right, Up, Down).\n",
        "\n",
        "#### How the Model is Constructed (`__init__` method):\n",
        "\n",
        "1.  **`super().__init__()`**: Calls the constructor of the parent class `nn.Module`.\n",
        "2.  **`self.lstm = nn.LSTM(...)`**: Defines the LSTM layer, which acts as the 'Temporal Encoder':\n",
        "    *   `input_size=num_channels`: Each time step of the input sequence will have `num_channels` features.\n",
        "    *   `hidden_size=hidden_size`: The size of the hidden state and cell state.\n",
        "    *   `num_layers=num_layers`: The depth of the LSTM network.\n",
        "    *   `batch_first=True`: Specifies that the input tensors will have the batch dimension as the first dimension `(batch, sequence_length, features)`.\n",
        "3.  **`self.classifier = nn.Linear(hidden_size, num_classes)`**: Defines a fully connected (linear) layer, which acts as the 'Classifier'. It takes the final hidden state of the LSTM (`hidden_size`) and maps it to the `num_classes` outputs.\n",
        "\n",
        "#### Forward Pass (`forward` method):\n",
        "\n",
        "This method defines how data flows through the network during inference or training.\n",
        "\n",
        "1.  **`x: (batch, C, T)`**: The input `x` is expected to be a batch of preprocessed signal windows, with dimensions `(batch_size, num_channels, num_timesteps_per_window)`.\n",
        "2.  **`x = x.permute(0, 2, 1)`**: The LSTM expects input in the format `(batch, sequence_length, features)`. Since our input is `(batch, num_channels, num_timesteps)`, we need to permute it to `(batch, num_timesteps, num_channels)`.\n",
        "3.  **`_, (h_n, _) = self.lstm(x)`**: The permuted input `x` is passed through the LSTM. The LSTM returns:\n",
        "    *   The output features for each time step (which we discard with `_` as we only need the final hidden state for classification).\n",
        "    *   The final hidden state (`h_n`) and final cell state (`c_n`). We only need `h_n`.\n",
        "4.  **`final_hidden = h_n[-1]`**: For a multi-layer LSTM, `h_n` will have a shape `(num_layers, batch, hidden_size)`. We take the hidden state of the last layer (`h_n[-1]`) which represents the aggregated information from the entire sequence.\n",
        "5.  **`logits = self.classifier(final_hidden)`**: The `final_hidden` state is passed through the linear classifier layer to produce the raw unnormalized scores (logits) for each of the `num_classes`. These logits can then be used with a softmax activation and cross-entropy loss for training.\n",
        "\n",
        "In summary, the `LSTMDecoder` processes time-series data using its recurrent nature to capture temporal dependencies and then classifies the learned representation into one of the predefined action categories."
      ],
      "id": "f546bd1f"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_channels: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        num_classes: int = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=num_channels,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, C, T)\n",
        "        x = x.permute(0, 2, 1)  # (batch, T, C)\n",
        "\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "\n",
        "        final_hidden = h_n[-1]  # (batch, hidden)\n",
        "        logits = self.classifier(final_hidden)\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "X3JZaVUx6RsS"
      },
      "id": "X3JZaVUx6RsS",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7094def4"
      },
      "source": [
        "### Training the Neural Signal Decoder\n",
        "\n",
        "This `main` function encapsulates the entire training pipeline for the `LSTMDecoder` model, leveraging the previously defined `SimulatedEEGDataset` and `LSTMDecoder` classes. It demonstrates how to prepare data, instantiate the model, set up the training loop, and evaluate performance.\n",
        "\n",
        "#### 1. Device Configuration:\n",
        "\n",
        "```python\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "```\n",
        "This line checks if a CUDA-enabled GPU is available. If so, it configures PyTorch to use the GPU for computations, which significantly speeds up training for deep learning models. Otherwise, it defaults to using the CPU.\n",
        "\n",
        "#### 2. Data Parameters:\n",
        "\n",
        "```python\n",
        "    num_channels = 16\n",
        "    total_timesteps = 1024\n",
        "    window_size = 256\n",
        "    stride = 128\n",
        "    num_samples_per_class = 50\n",
        "```\n",
        "These parameters define the characteristics of the simulated EEG data:\n",
        "*   `num_channels`: Number of EEG channels (e.g., electrodes).\n",
        "*   `total_timesteps`: Total length of the raw simulated signal before windowing.\n",
        "*   `window_size`: The length of each segment (window) of the signal that the model will process.\n",
        "*   `stride`: How much the window shifts for each new segment. A `stride` less than `window_size` creates overlapping windows.\n",
        "*   `num_samples_per_class`: The number of raw EEG signals generated for each of the 4 `class_id`s (Left, Right, Up, Down).\n",
        "\n",
        "#### 3. Model Parameters:\n",
        "\n",
        "```python\n",
        "    hidden_size = 128\n",
        "    num_layers = 2\n",
        "    num_classes = 4\n",
        "```\n",
        "These parameters are used to configure the `LSTMDecoder` model:\n",
        "*   `hidden_size`: The dimensionality of the hidden state in the LSTM layers. A larger `hidden_size` allows the LSTM to capture more complex patterns but increases computational cost.\n",
        "*   `num_layers`: The number of stacked LSTM layers. More layers can learn hierarchical representations but also increase model complexity.\n",
        "*   `num_classes`: The number of distinct output categories (actions) the model needs to classify (Left, Right, Up, Down, hence 4).\n",
        "\n",
        "#### 4. Training Parameters:\n",
        "\n",
        "```python\n",
        "    batch_size = 32\n",
        "    learning_rate = 1e-3\n",
        "    num_epochs = 10\n",
        "```\n",
        "These control the training process:\n",
        "*   `batch_size`: The number of samples processed in one forward/backward pass during training. Larger batches can lead to more stable gradients but require more memory.\n",
        "*   `learning_rate`: Determines the step size at each iteration while moving toward a minimum of the loss function. A smaller learning rate can lead to better convergence but slower training.\n",
        "*   `num_epochs`: The number of complete passes through the entire training dataset.\n",
        "\n",
        "#### 5. Dataset and DataLoader Initialization:\n",
        "\n",
        "```python\n",
        "    dataset = SimulatedEEGDataset(\n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        num_channels=num_channels,\n",
        "        total_timesteps=total_timesteps,\n",
        "        window_size=window_size,\n",
        "        stride=stride\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "```\n",
        "An instance of `SimulatedEEGDataset` is created, which generates and preprocesses all the synthetic EEG data according to the specified parameters. This dataset then feeds into a `DataLoader`, which batches the data, shuffles it (`shuffle=True` is important for training), and provides an iterable over the dataset for the training loop.\n",
        "\n",
        "#### 6. Model, Loss, and Optimizer Setup:\n",
        "\n",
        "```python\n",
        "    model = LSTMDecoder(\n",
        "        num_channels=num_channels,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_classes=num_classes\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "```\n",
        "*   **`model = LSTMDecoder(...)`**: An instance of our `LSTMDecoder` (Temporal Encoder & Classifier) is created with the defined model parameters. `.to(device)` moves the model to the GPU if available.\n",
        "*   **`criterion = nn.CrossEntropyLoss()`**: This is the loss function used for multi-class classification. It combines `LogSoftmax` and `NLLLoss` (Negative Log Likelihood Loss) and is commonly used when dealing with integer labels for classes.\n",
        "*   **`optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)`**: The Adam optimizer is chosen to adjust the model's weights during training to minimize the loss. `model.parameters()` tells the optimizer which parameters to update, and `lr` sets the learning rate.\n",
        "\n",
        "#### 7. Training Loop:\n",
        "\n",
        "```python\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "            f\"Loss: {avg_loss:.4f} \"\n",
        "            f\"Accuracy: {accuracy:.4f}\"\n",
        "        )\n",
        "```\n",
        "This is the core training logic:\n",
        "*   **`for epoch in range(num_epochs)`**: The outer loop iterates for the specified number of epochs.\n",
        "*   **`model.train()`**: Sets the model to training mode. This affects layers like `Dropout` and `BatchNorm`, ensuring they behave correctly during training.\n",
        "*   **Inner `for x, y in loader` loop**: Iterates through batches of data provided by the `DataLoader`.\n",
        "    *   `x = x.to(device)` and `y = y.to(device)`: Moves the input data (`x`, signal windows) and labels (`y`) to the configured device (GPU or CPU).\n",
        "    *   `logits = model(x)`: Performs a forward pass, feeding the input `x` through the `LSTMDecoder` to get raw predictions (logits).\n",
        "    *   `loss = criterion(logits, y)`: Calculates the loss between the model's predictions and the true labels.\n",
        "    *   `optimizer.zero_grad()`: Clears the gradients from the previous iteration. This is crucial before computing new gradients.\n",
        "    *   `loss.backward()`: Computes the gradients of the loss with respect to the model's parameters (backpropagation).\n",
        "    *   `optimizer.step()`: Updates the model's parameters using the computed gradients and the chosen optimization algorithm.\n",
        "*   **Metrics Calculation**: Inside the inner loop, `correct` predictions and `total` samples are tracked to calculate accuracy, and `total_loss` accumulates the loss for each batch.\n",
        "*   **Epoch Summary**: After each epoch, the average loss and accuracy are calculated and printed to the console, providing insight into the model's learning progress.\n",
        "\n",
        "#### 8. Entry Point:\n",
        "\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "This standard Python construct ensures that the `main()` function is called only when the script is executed directly (not when imported as a module)."
      ],
      "id": "7094def4"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data parameters\n",
        "    num_channels = 16\n",
        "    total_timesteps = 1024\n",
        "    window_size = 256\n",
        "    stride = 128\n",
        "    num_samples_per_class = 50\n",
        "\n",
        "    # Model parameters\n",
        "    hidden_size = 128\n",
        "    num_layers = 2\n",
        "    num_classes = 4\n",
        "\n",
        "    # Training parameters\n",
        "    batch_size = 32\n",
        "    learning_rate = 1e-3\n",
        "    num_epochs = 10\n",
        "\n",
        "    dataset = SimulatedEEGDataset(\n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        num_channels=num_channels,\n",
        "        total_timesteps=total_timesteps,\n",
        "        window_size=window_size,\n",
        "        stride=stride\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    model = LSTMDecoder(\n",
        "        num_channels=num_channels,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_classes=num_classes\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "            f\"Loss: {avg_loss:.4f} \"\n",
        "            f\"Accuracy: {accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRIu2Jmusa5T",
        "outputId": "dd727eb0-6c36-4945-a2c6-d754b2289ed2"
      },
      "id": "zRIu2Jmusa5T",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 1.3891 Accuracy: 0.2579\n",
            "Epoch [2/10] Loss: 1.3191 Accuracy: 0.3686\n",
            "Epoch [3/10] Loss: 1.1681 Accuracy: 0.4121\n",
            "Epoch [4/10] Loss: 1.1926 Accuracy: 0.3929\n",
            "Epoch [5/10] Loss: 1.1187 Accuracy: 0.4564\n",
            "Epoch [6/10] Loss: 1.1386 Accuracy: 0.4379\n",
            "Epoch [7/10] Loss: 1.3147 Accuracy: 0.3136\n",
            "Epoch [8/10] Loss: 1.3037 Accuracy: 0.2864\n",
            "Epoch [9/10] Loss: 1.1758 Accuracy: 0.4507\n",
            "Epoch [10/10] Loss: 1.1055 Accuracy: 0.5036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deeb4204"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "This `main` function is designed to evaluate the performance of a trained `LSTMDecoder` model. It utilizes the `SimulatedEEGDataset` to generate test data, performs inference, and then calculates and prints key classification metrics: overall accuracy, per-class accuracy, and a confusion matrix.\n",
        "\n",
        "#### 1. Device Configuration:\n",
        "\n",
        "```python\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "```\n",
        "This line configures PyTorch to use a CUDA-enabled GPU if available, otherwise it defaults to the CPU. This ensures that the model inference benefits from hardware acceleration if present.\n",
        "\n",
        "#### 2. Data and Model Parameters:\n",
        "\n",
        "```python\n",
        "    num_channels = 16\n",
        "    total_timesteps = 1024\n",
        "    window_size = 256\n",
        "    stride = 128\n",
        "    num_samples_per_class = 20\n",
        "\n",
        "    hidden_size = 128\n",
        "    num_layers = 2\n",
        "    num_classes = 4\n",
        "    batch_size = 32\n",
        "```\n",
        "These parameters are similar to those used during training. They define:\n",
        "*   The characteristics of the simulated EEG data (`num_channels`, `total_timesteps`, `window_size`, `stride`, `num_samples_per_class`). Note that `num_samples_per_class` is set to `20` here, which is typically smaller than the training set, to generate a dedicated evaluation set.\n",
        "*   The architecture of the `LSTMDecoder` model (`hidden_size`, `num_layers`, `num_classes`).\n",
        "*   The `batch_size` for processing data during inference.\n",
        "\n",
        "#### 3. Dataset and DataLoader Initialization:\n",
        "\n",
        "```python\n",
        "    dataset = SimulatedEEGDataset(\n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        num_channels=num_channels,\n",
        "        total_timesteps=total_timesteps,\n",
        "        window_size=window_size,\n",
        "        stride=stride\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "```\n",
        "An instance of `SimulatedEEGDataset` is created to generate a fresh set of simulated EEG data for evaluation. A `DataLoader` is then initialized:\n",
        "*   `batch_size`: Data is processed in batches.\n",
        "*   `shuffle=False`: Crucially, the data is **not shuffled** during evaluation. This ensures that predictions and labels can be consistently matched and aggregated for calculating metrics.\n",
        "\n",
        "#### 4. Model Initialization and Evaluation Mode:\n",
        "\n",
        "```python\n",
        "    model = LSTMDecoder(\n",
        "        num_channels=num_channels,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_classes=num_classes\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "```\n",
        "*   An `LSTMDecoder` instance is created with the specified architecture and moved to the chosen device (GPU/CPU).\n",
        "*   **`model.eval()`**: This call sets the model to evaluation mode. As discussed previously, this is vital because it disables specific layers like `Dropout` and uses accumulated running statistics for `Batch Normalization` layers. This ensures consistent and deterministic predictions, preventing any training-specific behaviors from influencing the evaluation results.\n",
        "\n",
        "#### 5. Inference Loop and Prediction Collection:\n",
        "\n",
        "```python\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(y.cpu().numpy())\n",
        "```\n",
        "*   **`with torch.no_grad():`**: This context manager is used to disable gradient calculation during inference. This significantly reduces memory consumption and speeds up computation, as backpropagation is not needed for evaluation.\n",
        "*   The loop iterates through each batch of the evaluation dataset:\n",
        "    *   Input `x` (signal windows) and true labels `y` are moved to the designated device.\n",
        "    *   `logits = model(x)`: The model performs a forward pass to generate raw prediction scores (logits).\n",
        "    *   `preds = logits.argmax(dim=1)`: The `argmax` function is used to convert the logits into predicted class IDs by selecting the class with the highest score for each sample in the batch.\n",
        "    *   The predictions (`preds`) and true labels (`y`) are moved back to the CPU (`.cpu()`) and converted to NumPy arrays (`.numpy()`) before being appended to their respective lists.\n",
        "\n",
        "#### 6. Metric Computation:\n",
        "\n",
        "```python\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    confusion = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "    for t, p in zip(all_labels, all_preds):\n",
        "        confusion[t, p] += 1\n",
        "\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    per_class_acc = confusion.diagonal() / confusion.sum(axis=1)\n",
        "```\n",
        "After collecting all predictions and true labels from the entire dataset:\n",
        "*   `np.concatenate`: The lists of batch-wise predictions and labels are concatenated into single NumPy arrays.\n",
        "*   **Confusion Matrix**: An empty `num_classes` x `num_classes` matrix is initialized. The code then iterates through all true-prediction pairs, incrementing the count at `confusion[true_label, predicted_label]`. This matrix provides a detailed breakdown of correct and incorrect classifications for each class.\n",
        "*   **Overall Accuracy**: Calculated as the proportion of correctly predicted samples out of the total samples `(all_preds == all_labels).mean()`.\n",
        "*   **Per-Class Accuracy**: Derived from the confusion matrix. `confusion.diagonal()` gives the number of correct predictions for each class, and `confusion.sum(axis=1)` gives the total number of actual instances for each class. Dividing these provides the accuracy for each individual class.\n",
        "\n",
        "#### 7. Printing Results:\n",
        "\n",
        "```python\n",
        "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    for i, acc in enumerate(per_class_acc):\n",
        "        print(f\"Class {i} Accuracy: {acc:.4f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion)\n",
        "```\n",
        "Finally, the computed overall accuracy, individual class accuracies, and the full confusion matrix are printed to the console, providing a comprehensive view of the model's performance on the simulated EEG decoding task.\n",
        "\n",
        "#### 8. Entry Point:\n",
        "\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "This standard Python construct ensures that the `main()` function is called only when the script is executed directly (not when imported as a module)."
      ],
      "id": "deeb4204"
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    num_channels = 16\n",
        "    total_timesteps = 1024\n",
        "    window_size = 256\n",
        "    stride = 128\n",
        "    num_samples_per_class = 20\n",
        "\n",
        "    hidden_size = 128\n",
        "    num_layers = 2\n",
        "    num_classes = 4\n",
        "    batch_size = 32\n",
        "\n",
        "    dataset = SimulatedEEGDataset(\n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        num_channels=num_channels,\n",
        "        total_timesteps=total_timesteps,\n",
        "        window_size=window_size,\n",
        "        stride=stride\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = LSTMDecoder(\n",
        "        num_channels=num_channels,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_classes=num_classes\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(y.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    confusion = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "    for t, p in zip(all_labels, all_preds):\n",
        "        confusion[t, p] += 1\n",
        "\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    per_class_acc = confusion.diagonal() / confusion.sum(axis=1)\n",
        "\n",
        "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    for i, acc in enumerate(per_class_acc):\n",
        "        print(f\"Class {i} Accuracy: {acc:.4f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBNFfW84wzxt",
        "outputId": "d27cace0-0a5f-40ae-e750-3e3755a53025"
      },
      "id": "gBNFfW84wzxt",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.2482\n",
            "Class 0 Accuracy: 0.8714\n",
            "Class 1 Accuracy: 0.1214\n",
            "Class 2 Accuracy: 0.0000\n",
            "Class 3 Accuracy: 0.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[122  17   1   0]\n",
            " [123  17   0   0]\n",
            " [132   8   0   0]\n",
            " [134   6   0   0]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}